{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets transformers tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:43:32.330241Z","iopub.execute_input":"2025-07-04T13:43:32.330463Z","iopub.status.idle":"2025-07-04T13:43:37.265141Z","shell.execute_reply.started":"2025-07-04T13:43:32.330438Z","shell.execute_reply":"2025-07-04T13:43:37.264395Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install tensorflow-model-optimization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:43:37.266066Z","iopub.execute_input":"2025-07-04T13:43:37.266328Z","iopub.status.idle":"2025-07-04T13:43:40.678901Z","shell.execute_reply.started":"2025-07-04T13:43:37.266295Z","shell.execute_reply":"2025-07-04T13:43:40.678169Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow-model-optimization\n  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\nRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\nRequirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\nRequirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\nRequirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.17.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy~=1.23->tensorflow-model-optimization) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow-model-optimization\nSuccessfully installed tensorflow-model-optimization-0.8.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\nfrom datasets import load_dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_model_optimization as tfmot\nimport tensorflow.lite as tflite\nimport time\nimport os\nimport contextlib\n\n# Step 1: Set up TPU (optional, skip for GPU/CPU)\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = None  # Use GPU/CPU if TPU not available\n    print('No TPU detected, running on GPU/CPU')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:43:46.393412Z","iopub.execute_input":"2025-07-04T13:43:46.393925Z","iopub.status.idle":"2025-07-04T13:44:12.631190Z","shell.execute_reply.started":"2025-07-04T13:43:46.393891Z","shell.execute_reply":"2025-07-04T13:44:12.630520Z"}},"outputs":[{"name":"stderr","text":"2025-07-04 13:43:47.725517: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751636627.896918      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751636627.948506      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"No TPU detected, running on GPU/CPU\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Step 2: Install required packages (if not already installed in Kaggle)\n!pip install tensorflow-model-optimization\n!pip install ipywidgets  # For TqdmWarning, if needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:46:06.866460Z","iopub.execute_input":"2025-07-04T13:46:06.867206Z","iopub.status.idle":"2025-07-04T13:46:12.837232Z","shell.execute_reply.started":"2025-07-04T13:46:06.867181Z","shell.execute_reply":"2025-07-04T13:46:12.836452Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.11/dist-packages (0.8.0)\nRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\nRequirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\nRequirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\nRequirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.17.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy~=1.23->tensorflow-model-optimization) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load and preprocess the SST-2 dataset\ndataset = load_dataset(\"glue\", \"sst2\")\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\ndef tokenize_function(examples):\n    return tokenizer(examples['sentence'], padding='max_length', truncation=True, max_length=128)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:46:20.513627Z","iopub.execute_input":"2025-07-04T13:46:20.514445Z","iopub.status.idle":"2025-07-04T13:46:43.020740Z","shell.execute_reply.started":"2025-07-04T13:46:20.514412Z","shell.execute_reply":"2025-07-04T13:46:43.020132Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee243d6296a24035bc2f26e7232d2b68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582258700fbb4a65bb0298b45c198693"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1d674180d3406a87738ba3210f1921"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df76b765fcb64b2abf65f38e66ac5534"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc20a876f53473a9a3b1a75d29ba02c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c57bee1ea7e470692756226023aae22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23a9964e17a94a1f8dd16d3fd644adbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f8bb24474a41c4ab7370062d65df6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778447bfe0234fd895391cc39cd2d3fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4cd80fdb1744a8aab841172641aef2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a4b8b202064e37b718cb91a6b473fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4950a5353623420e979fbde3d3532034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3deb4713288c415199a7f9030666d95a"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Prepare tf.data.Dataset (excluding token_type_ids)\nfrom transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n\ntf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n    columns=[\"input_ids\", \"attention_mask\"],\n    label_cols=[\"label\"],\n    shuffle=True,\n    batch_size=16,\n    collate_fn=data_collator\n)\n\ntf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n    columns=[\"input_ids\", \"attention_mask\"],\n    label_cols=[\"label\"],\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:46:47.190651Z","iopub.execute_input":"2025-07-04T13:46:47.190986Z","iopub.status.idle":"2025-07-04T13:46:47.963377Z","shell.execute_reply.started":"2025-07-04T13:46:47.190962Z","shell.execute_reply":"2025-07-04T13:46:47.962567Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\nOld behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \nNew behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n  warnings.warn(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Step 4: Fine-tune baseline DistilBERT\nwith contextlib.nullcontext():\n    baseline_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n    baseline_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n    )\n    baseline_model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)\n\n# Save baseline model in SavedModel format\nbaseline_model.save('baseline_model', save_format='tf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:47:17.595831Z","iopub.execute_input":"2025-07-04T13:47:17.596424Z","iopub.status.idle":"2025-07-04T14:15:23.928448Z","shell.execute_reply.started":"2025-07-04T13:47:17.596397Z","shell.execute_reply":"2025-07-04T14:15:23.927597Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751636859.550089     125 service.cc:148] XLA service 0x7b6ba4682da0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1751636859.550877     125 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1751636859.623604     125 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1751636859.767174     125 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"4210/4210 [==============================] - 575s 130ms/step - loss: 0.2185 - accuracy: 0.9149 - val_loss: 0.2462 - val_accuracy: 0.8945\nEpoch 2/3\n4210/4210 [==============================] - 541s 128ms/step - loss: 0.1183 - accuracy: 0.9585 - val_loss: 0.2535 - val_accuracy: 0.8888\nEpoch 3/3\n4210/4210 [==============================] - 541s 129ms/step - loss: 0.0816 - accuracy: 0.9714 - val_loss: 0.3622 - val_accuracy: 0.8784\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Step 5: Apply pruning (only to classification head)\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.0,\n        final_sparsity=0.5,\n        begin_step=0,\n        end_step=len(tf_train_dataset) * 3\n    )\n}\n\nwith contextlib.nullcontext():\n    # Create a new Functional model\n    input_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n    attention_mask = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n    transformer_outputs = baseline_model.distilbert(input_ids, attention_mask=attention_mask)[0]\n    cls_token = transformer_outputs[:, 0, :]  # Take [CLS] token\n    # Apply pruning to dense layers only\n    pre_classifier = tfmot.sparsity.keras.prune_low_magnitude(\n        tf.keras.layers.Dense(768, activation='relu', name='pre_classifier'),\n        **pruning_params\n    )(cls_token)\n    classifier = tfmot.sparsity.keras.prune_low_magnitude(\n        tf.keras.layers.Dense(2, name='classifier'),\n        **pruning_params\n    )(pre_classifier)\n    functional_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=classifier)\n\n    # Copy weights from baseline_model to functional_model\n    for layer in functional_model.layers:\n        if layer.name in ['pre_classifier', 'classifier']:\n            layer_wo_pruning = baseline_model.get_layer(layer.name)\n            layer.set_weights(layer_wo_pruning.get_weights())\n\n    # Compile and train the pruned model\n    functional_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n    )\n    functional_model.fit(\n        tf_train_dataset,\n        validation_data=tf_validation_dataset,\n        epochs=3,\n        callbacks=[tfmot.sparsity.keras.UpdatePruningStep()]\n    )\n\n# Strip pruning wrappers\nfinal_pruned_model = tfmot.sparsity.keras.strip_pruning(functional_model)\nfinal_pruned_model.save('pruned_model', save_format='tf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:02:11.578072Z","iopub.execute_input":"2025-07-04T15:02:11.578669Z","iopub.status.idle":"2025-07-04T15:30:15.885113Z","shell.execute_reply.started":"2025-07-04T15:02:11.578643Z","shell.execute_reply":"2025-07-04T15:30:15.884501Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n4210/4210 [==============================] - 577s 131ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 0.3848 - val_accuracy: 0.8979\nEpoch 2/3\n4210/4210 [==============================] - 543s 129ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.3744 - val_accuracy: 0.8750\nEpoch 3/3\n4210/4210 [==============================] - 543s 129ms/step - loss: 0.0417 - accuracy: 0.9850 - val_loss: 0.5721 - val_accuracy: 0.8739\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!pip install tensorflow==2.15.0 transformers==4.37.0 datasets==2.15.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T14:50:44.820006Z","iopub.execute_input":"2025-07-04T14:50:44.820546Z","iopub.status.idle":"2025-07-04T14:51:45.748429Z","shell.execute_reply.started":"2025-07-04T14:50:44.820506Z","shell.execute_reply":"2025-07-04T14:51:45.747595Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.15.0\n  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting transformers==4.37.0\n  Downloading transformers-4.37.0-py3-none-any.whl.metadata (129 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting datasets==2.15.0\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.13.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\nCollecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.13.2)\nCollecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.72.0rc1)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (2.32.3)\nCollecting tokenizers<0.19,>=0.14 (from transformers==4.37.0)\n  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (4.67.1)\nRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (19.0.1)\nCollecting pyarrow-hotfix (from datasets==2.15.0)\n  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.15.0)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (3.11.18)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.20.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (2025.4.26)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.40.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.15.0)\n  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2025.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\nDownloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\nInstalling collected packages: wrapt, tensorflow-estimator, pyarrow-hotfix, keras, fsspec, dill, multiprocess, tokenizers, tensorboard, ml-dtypes, transformers, tensorflow, datasets\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.17.2\n    Uninstalling wrapt-1.17.2:\n      Successfully uninstalled wrapt-1.17.2\n  Attempting uninstall: keras\n    Found existing installation: keras 3.8.0\n    Uninstalling keras-3.8.0:\n      Successfully uninstalled keras-3.8.0\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.0\n    Uninstalling fsspec-2025.3.0:\n      Successfully uninstalled fsspec-2025.3.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.1\n    Uninstalling tokenizers-0.21.1:\n      Successfully uninstalled tokenizers-0.21.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.3\n    Uninstalling transformers-4.51.3:\n      Successfully uninstalled transformers-4.51.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.6.0\n    Uninstalling datasets-3.6.0:\n      Successfully uninstalled datasets-3.6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\njax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.10.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\nopentelemetry-api 1.31.1 requires importlib-metadata<8.7.0,>=6.0, but you have importlib-metadata 8.7.0 which is incompatible.\ntensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 fsspec-2023.10.0 keras-2.15.0 ml-dtypes-0.2.0 multiprocess-0.70.15 pyarrow-hotfix-0.7 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tokenizers-0.15.2 transformers-4.37.0 wrapt-1.14.1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Step 6: Knowledge Distillation\nteacher_model = tf.keras.models.load_model('baseline_model')\nteacher_model.trainable = False\nstudent_model = final_pruned_model\n\ndef kd_loss(y_true, student_logits, teacher_logits, alpha=0.5, T=2):\n    ce_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, student_logits, from_logits=True)\n    ce_loss = tf.reduce_mean(ce_loss)\n    \n    student_logits_soft = student_logits / T\n    teacher_logits_soft = teacher_logits / T\n    student_probs = tf.nn.softmax(student_logits_soft)\n    teacher_probs = tf.nn.softmax(teacher_logits_soft)\n    \n    kl_loss = tf.keras.losses.kullback_leibler_divergence(teacher_probs, student_probs)\n    kl_loss = tf.reduce_mean(kl_loss)\n    \n    return (1 - alpha) * ce_loss + alpha * (T ** 2) * kl_loss\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\nstudent_model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n\n# Custom training loop for KD\nepochs = 3\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    for step, (x_batch, y_batch) in enumerate(tf_train_dataset):\n        # Rename input keys to match teacher model's expected signature\n        x_batch_teacher = {\n            'input_ids_input_ids': x_batch['input_ids'],\n            'attention_mask': x_batch['attention_mask']\n        }\n        with tf.GradientTape() as tape:\n            student_outputs = student_model(x_batch, training=True)\n            teacher_outputs = teacher_model(x_batch_teacher, training=False)\n            loss = kd_loss(y_batch, student_outputs.logits if hasattr(student_outputs, 'logits') else student_outputs, teacher_outputs.logits)\n        grads = tape.gradient(loss, student_model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n        if step % 100 == 0:\n            print(f\"Step {step}, Loss: {loss.numpy()}\")\n\nkd_optimized_model = student_model\nkd_optimized_model.save('kd_optimized_model', save_format='tf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:46:33.704295Z","iopub.execute_input":"2025-07-04T15:46:33.704957Z","iopub.status.idle":"2025-07-04T15:46:51.895381Z","shell.execute_reply.started":"2025-07-04T15:46:33.704932Z","shell.execute_reply":"2025-07-04T15:46:51.894179Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/657525134.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mstudent_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mteacher_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_teacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logits'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstudent_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m           \"Option {}:\\n  {}\\n  Keyword arguments: {}\".format(\n\u001b[1;32m    334\u001b[0m               index + 1, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 335\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;34m\"Could not find matching concrete function to call loaded from the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;34mf\"SavedModel. Got:\\n  {_pretty_format_positional(args)}\\n  Keyword \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (9 total):\n    * {'attention_mask': <tf.Tensor 'input_ids_1:0' shape=(16, 128) dtype=int64>,\n 'input_ids_input_ids': <tf.Tensor 'input_ids:0' shape=(16, 128) dtype=int64>}\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (9 total):\n    * {'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'),\n 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids')}\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * True\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (9 total):\n    * {'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'),\n 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids')}\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * False\n  Keyword arguments: {}\n\nCall arguments received by layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification):\n  • attention_mask={'input_ids_input_ids': 'tf.Tensor(shape=(16, 128), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(16, 128), dtype=int64)'}\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • labels=None\n  • training=False"],"ename":"ValueError","evalue":"Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (9 total):\n    * {'attention_mask': <tf.Tensor 'input_ids_1:0' shape=(16, 128) dtype=int64>,\n 'input_ids_input_ids': <tf.Tensor 'input_ids:0' shape=(16, 128) dtype=int64>}\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (9 total):\n    * {'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'),\n 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids')}\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * True\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (9 total):\n    * {'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'),\n 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids')}\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * None\n    * False\n  Keyword arguments: {}\n\nCall arguments received by layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification):\n  • attention_mask={'input_ids_input_ids': 'tf.Tensor(shape=(16, 128), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(16, 128), dtype=int64)'}\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • labels=None\n  • training=False","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\nfrom datasets import load_dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_model_optimization as tfmot\nimport tensorflow.lite as tflite\nimport time\nimport os\nimport contextlib\n\n# Step 1: Environment setup (GPU/CPU)\nstrategy = None\nprint('Running on GPU/CPU')\n\n# Step 2: Install required packages\n!pip install tensorflow-model-optimization\n!pip install ipywidgets  # For TqdmWarning, if needed\n\n# Step 3: Load and preprocess the SST-2 dataset\ndataset = load_dataset(\"glue\", \"sst2\")\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\ndef tokenize_function(examples):\n    return tokenizer(examples['sentence'], padding='max_length', truncation=True, max_length=128)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# Prepare tf.data.Dataset (excluding token_type_ids, ensure int32)\nfrom transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n\ntf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n    columns=[\"input_ids\", \"attention_mask\"],\n    label_cols=[\"label\"],\n    shuffle=True,\n    batch_size=16,\n    collate_fn=data_collator\n).map(lambda x, y: ({'input_ids': tf.cast(x['input_ids'], tf.int32), 'attention_mask': tf.cast(x['attention_mask'], tf.int32)}, y))\n\ntf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n    columns=[\"input_ids\", \"attention_mask\"],\n    label_cols=[\"label\"],\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator\n).map(lambda x, y: ({'input_ids': tf.cast(x['input_ids'], tf.int32), 'attention_mask': tf.cast(x['attention_mask'], tf.int32)}, y))\n\n# Step 4: Fine-tune baseline DistilBERT\nwith contextlib.nullcontext():\n    baseline_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n    baseline_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n    )\n    baseline_model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)\n\n# Save baseline model in SavedModel format\nbaseline_model.save('baseline_model', save_format='tf')\n\n# Step 5: Apply pruning (only to classification head)\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.0,\n        final_sparsity=0.5,\n        begin_step=0,\n        end_step=len(tf_train_dataset) * 3\n    )\n}\n\nwith contextlib.nullcontext():\n    # Create a new Functional model\n    input_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n    attention_mask = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n    transformer_outputs = baseline_model.distilbert(input_ids, attention_mask=attention_mask)[0]\n    cls_token = transformer_outputs[:, 0, :]  # Take [CLS] token\n    # Apply pruning to dense layers only\n    pre_classifier = tfmot.sparsity.keras.prune_low_magnitude(\n        tf.keras.layers.Dense(768, activation='relu', name='pre_classifier'),\n        **pruning_params\n    )(cls_token)\n    classifier = tfmot.sparsity.keras.prune_low_magnitude(\n        tf.keras.layers.Dense(2, name='classifier'),\n        **pruning_params\n    )(pre_classifier)\n    functional_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=classifier)\n\n    # Copy weights from baseline_model to functional_model\n    for layer in functional_model.layers:\n        if layer.name in ['pre_classifier', 'classifier']:\n            layer_wo_pruning = baseline_model.get_layer(layer.name)\n            layer.set_weights(layer_wo_pruning.get_weights())\n\n    # Compile and train the pruned model\n    functional_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n    )\n    functional_model.fit(\n        tf_train_dataset,\n        validation_data=tf_validation_dataset,\n        epochs=3,\n        callbacks=[tfmot.sparsity.keras.UpdatePruningStep()]\n    )\n\n# Strip pruning wrappers\nfinal_pruned_model = tfmot.sparsity.keras.strip_pruning(functional_model)\nfinal_pruned_model.save('pruned_model', save_format='tf')\n\n# Step 6: Knowledge Distillation\nteacher_model = tf.keras.models.load_model('baseline_model')\nteacher_model.trainable = False\nstudent_model = final_pruned_model\n\ndef kd_loss(y_true, student_logits, teacher_logits, alpha=0.5, T=2):\n    ce_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, student_logits, from_logits=True)\n    ce_loss = tf.reduce_mean(ce_loss)\n    \n    student_logits_soft = student_logits / T\n    teacher_logits_soft = teacher_logits / T\n    student_probs = tf.nn.softmax(student_logits_soft)\n    teacher_probs = tf.nn.softmax(teacher_logits_soft)\n    \n    kl_loss = tf.keras.losses.kullback_leibler_divergence(teacher_probs, student_probs)\n    kl_loss = tf.reduce_mean(kl_loss)\n    \n    return (1 - alpha) * ce_loss + alpha * (T ** 2) * kl_loss\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\nstudent_model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n\n# Custom training loop for KD\nepochs = 3\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    for step, (x_batch, y_batch) in enumerate(tf_train_dataset):\n        # Cast inputs to int32 and use correct input keys\n        x_batch_teacher = {\n            'input_ids': tf.cast(x_batch['input_ids'], tf.int32),\n            'attention_mask': tf.cast(x_batch['attention_mask'], tf.int32)\n        }\n        with tf.GradientTape() as tape:\n            student_outputs = student_model(x_batch, training=True)\n            teacher_outputs = teacher_model(x_batch_teacher, training=False)\n            loss = kd_loss(y_batch, student_outputs.logits if hasattr(student_outputs, 'logits') else student_outputs, teacher_outputs.logits)\n        grads = tape.gradient(loss, student_model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n        if step % 100 == 0:\n            print(f\"Step {step}, Loss: {loss.numpy()}\")\n\nkd_optimized_model = student_model\nkd_optimized_model.save('kd_optimized_model', save_format='tf')\n\n# Step 7: Post-Training Quantization\ncalibration_data = tokenized_datasets[\"train\"].select(range(100))\n\ndef representative_dataset():\n    for i in range(100):\n        sample = calibration_data[i]\n        yield [\n            np.array(sample['input_ids'], dtype=np.int32)[np.newaxis, :],\n            np.array(sample['attention_mask'], dtype=np.int32)[np.newaxis, :]\n        ]\n\nconverter = tf.lite.TFLiteConverter.from_saved_model('kd_optimized_model')\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_dataset\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.int8\nconverter.inference_output_type = tf.int8\ntflite_model = converter.convert()\n\nwith open('tflite_model.tflite', 'wb') as f:\n    f.write(tflite_model)\n\n# Step 8: Evaluation\ndef compute_accuracy(model, dataset):\n    total_correct = 0\n    total_samples = 0\n    for x_batch, y_batch in dataset:\n        # Adjust input for teacher model (TFDistilBertForSequenceClassification)\n        x_batch_input = {\n            'input_ids': tf.cast(x_batch['input_ids'], tf.int32),\n            'attention_mask': tf.cast(x_batch['attention_mask'], tf.int32)\n        } if isinstance(model, TFDistilBertForSequenceClassification) else x_batch\n        outputs = model(x_batch_input, training=False)\n        logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n        predictions = tf.argmax(logits, axis=1)\n        total_correct += tf.reduce_sum(tf.cast(predictions == y_batch, tf.int32)).numpy()\n        total_samples += y_batch.shape[0]\n    return total_correct / total_samples\n\ndef compute_tflite_accuracy(tflite_model_path, dataset):\n    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    \n    total_correct = 0\n    total_samples = 0\n    for x_batch, y_batch in dataset:\n        for i in range(x_batch['input_ids'].shape[0]):\n            interpreter.set_tensor(input_details[0]['index'], tf.cast(x_batch['input_ids'][i:i+1], tf.int32))\n            interpreter.set_tensor(input_details[1]['index'], tf.cast(x_batch['attention_mask'][i:i+1], tf.int32))\n            interpreter.invoke()\n            logits = interpreter.get_tensor(output_details[0]['index'])\n            prediction = np.argmax(logits, axis=1)\n            total_correct += (prediction == y_batch[i].numpy()).sum()\n            total_samples += 1\n    return total_correct / total_samples\n\ndef measure_inference_time(model, dataset, num_samples=100):\n    start_time = time.time()\n    count = 0\n    for x_batch, _ in dataset:\n        x_batch_input = {\n            'input_ids': tf.cast(x_batch['input_ids'], tf.int32),\n            'attention_mask': tf.cast(x_batch['attention_mask'], tf.int32)\n        } if isinstance(model, TFDistilBertForSequenceClassification) else x_batch\n        model(x_batch_input, training=False)\n        count += x_batch['input_ids'].shape[0]\n        if count >= num_samples:\n            break\n    return (time.time() - start_time) / num_samples * 1000  # ms per sample\n\ndef measure_tflite_inference_time(tflite_model_path, dataset, num_samples=100):\n    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    start_time = time.time()\n    count = 0\n    for x_batch, _ in dataset:\n        for i in range(x_batch['input_ids'].shape[0]):\n            interpreter.set_tensor(input_details[0]['index'], tf.cast(x_batch['input_ids'][i:i+1], tf.int32))\n            interpreter.set_tensor(input_details[1]['index'], tf.cast(x_batch['attention_mask'][i:i+1], tf.int32))\n            interpreter.invoke()\n            count += 1\n            if count >= num_samples:\n                break\n    return (time.time() - start_time) / num_samples * 1000  # ms per sample\n\n# Compute metrics\nbaseline_model = tf.keras.models.load_model('baseline_model')\npruned_model = tf.keras.models.load_model('pruned_model')\nkd_optimized_model = tf.keras.models.load_model('kd_optimized_model')\n\nbaseline_accuracy = compute_accuracy(baseline_model, tf_validation_dataset)\npruned_accuracy = compute_accuracy(pruned_model, tf_validation_dataset)\nkd_accuracy = compute_accuracy(kd_optimized_model, tf_validation_dataset)\ntflite_accuracy = compute_tflite_accuracy('tflite_model.tflite', tf_validation_dataset)\n\nbaseline_size = sum(os.path.getsize(os.path.join('baseline_model', f)) for f in os.listdir('baseline_model') if os.path.isfile(os.path.join('baseline_model', f))) / (1024 * 1024)  # MB\npruned_size = sum(os.path.getsize(os.path.join('pruned_model', f)) for f in os.listdir('pruned_model') if os.path.isfile(os.path.join('pruned_model', f))) / (1024 * 1024)  # MB\nkd_size = sum(os.path.getsize(os.path.join('kd_optimized_model', f)) for f in os.listdir('kd_optimized_model') if os.path.isfile(os.path.join('kd_optimized_model', f))) / (1024 * 1024)  # MB\ntflite_size = os.path.getsize('tflite_model.tflite') / (1024 * 1024)  # MB\n\nbaseline_latency = measure_inference_time(baseline_model, tf_validation_dataset)\npruned_latency = measure_inference_time(pruned_model, tf_validation_dataset)\nkd_latency = measure_inference_time(kd_optimized_model, tf_validation_dataset)\ntflite_latency = measure_tflite_inference_time('tflite_model.tflite', tf_validation_dataset)\n\n# Step 9: Plotting\nmetrics = {\n    'Model': ['Baseline', 'Pruned', 'Distilled', 'Quantized'],\n    'Accuracy': [baseline_accuracy * 100, pruned_accuracy * 100, kd_accuracy * 100, tflite_accuracy * 100],\n    'Size (MB)': [baseline_size, pruned_size, kd_size, tflite_size],\n    'Latency (ms)': [baseline_latency, pruned_latency, kd_latency, tflite_latency]\n}\n\n# Note: The actual plotting is handled by the ChartJS block below\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 3, 1)\nplt.bar(metrics['Model'], metrics['Accuracy'])\nplt.title('Accuracy (%)')\nplt.subplot(1, 3, 2)\nplt.bar(metrics['Model'], metrics['Size (MB)'])\nplt.title('Model Size (MB)')\nplt.subplot(1, 3, 3)\nplt.bar(metrics['Model'], metrics['Latency (ms)'])\nplt.title('Inference Latency (ms)')\nplt.tight_layout()\nplt.show()\n\nprint(\"Metrics Table:\")\nprint(\"| Model     | Accuracy (%) | Size (MB) | Latency (ms) |\")\nprint(\"|-----------|--------------|-----------|--------------|\")\nfor i in range(4):\n    print(f\"| {metrics['Model'][i]:<9} | {metrics['Accuracy'][i]:<12.2f} | {metrics['Size (MB)'][i]:<9.2f} | {metrics['Latency (ms)'][i]:<12.2f} |\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:48:26.572596Z","iopub.execute_input":"2025-07-04T15:48:26.572883Z","iopub.status.idle":"2025-07-04T16:45:01.829456Z","shell.execute_reply.started":"2025-07-04T15:48:26.572862Z","shell.execute_reply":"2025-07-04T16:45:01.828246Z"}},"outputs":[{"name":"stdout","text":"Running on GPU/CPU\nRequirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.11/dist-packages (0.8.0)\nRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\nRequirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\nRequirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\nRequirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.14.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy~=1.23->tensorflow-model-optimization) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\nOld behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \nNew behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n  warnings.warn(\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n4210/4210 [==============================] - 570s 130ms/step - loss: 0.2183 - accuracy: 0.9143 - val_loss: 0.2759 - val_accuracy: 0.8968\nEpoch 2/3\n4210/4210 [==============================] - 542s 129ms/step - loss: 0.1170 - accuracy: 0.9587 - val_loss: 0.3519 - val_accuracy: 0.8773\nEpoch 3/3\n4210/4210 [==============================] - 541s 129ms/step - loss: 0.0828 - accuracy: 0.9710 - val_loss: 0.2952 - val_accuracy: 0.8888\nEpoch 1/3\n4210/4210 [==============================] - 572s 130ms/step - loss: 0.0637 - accuracy: 0.9777 - val_loss: 0.4093 - val_accuracy: 0.8727\nEpoch 2/3\n4210/4210 [==============================] - 543s 129ms/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 0.4615 - val_accuracy: 0.8739\nEpoch 3/3\n4210/4210 [==============================] - 545s 129ms/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 0.5739 - val_accuracy: 0.8739\nEpoch 1/3\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/478980925.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mstudent_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mteacher_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_teacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logits'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstudent_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'logits'"],"ename":"AttributeError","evalue":"'dict' object has no attribute 'logits'","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\nfrom datasets import load_dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_model_optimization as tfmot\nimport tensorflow.lite as tflite\nimport time\nimport os\nimport contextlib\n\n# Step 1: Environment setup (GPU/CPU)\nstrategy = None\nprint('Running on GPU/CPU')\n\n# Step 2: Install required packages\n!pip install tensorflow-model-optimization\n!pip install ipywidgets  # For TqdmWarning, if needed\n\n# Step 3: Load and preprocess the SST-2 dataset\ndataset = load_dataset(\"glue\", \"sst2\")\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\ndef tokenize_function(examples):\n    return tokenizer(examples['sentence'], padding='max_length', truncation=True, max_length=128)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# Prepare tf.data.Dataset (excluding token_type_ids, ensure int32)\nfrom transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n\ntf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n    columns=[\"input_ids\", \"attention_mask\"],\n    label_cols=[\"label\"],\n    shuffle=True,\n    batch_size=16,\n    collate_fn=data_collator\n).map(lambda x, y: ({'input_ids': tf.cast(x['input_ids'], tf.int32), 'attention_mask': tf.cast(x['attention_mask'], tf.int32)}, y))\n\ntf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n    columns=[\"input_ids\", \"attention_mask\"],\n    label_cols=[\"label\"],\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator\n).map(lambda x, y: ({'input_ids': tf.cast(x['input_ids'], tf.int32), 'attention_mask': tf.cast(x['attention_mask'], tf.int32)}, y))\n\n# Step 4: Fine-tune baseline DistilBERT\nwith contextlib.nullcontext():\n    baseline_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n    baseline_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n    )\n    baseline_model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)\n\n# Save baseline model in SavedModel format\nbaseline_model.save('baseline_model', save_format='tf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:55:31.193772Z","iopub.execute_input":"2025-07-04T16:55:31.194087Z","iopub.status.idle":"2025-07-04T17:23:45.166379Z","shell.execute_reply.started":"2025-07-04T16:55:31.194064Z","shell.execute_reply":"2025-07-04T17:23:45.165728Z"}},"outputs":[{"name":"stdout","text":"Running on GPU/CPU\nRequirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.11/dist-packages (0.8.0)\nRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\nRequirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\nRequirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\nRequirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.14.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy~=1.23->tensorflow-model-optimization) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy~=1.23->tensorflow-model-optimization) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy~=1.23->tensorflow-model-optimization) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy~=1.23->tensorflow-model-optimization) (2024.2.0)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\nOld behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \nNew behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n  warnings.warn(\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n4210/4210 [==============================] - 571s 130ms/step - loss: 0.2184 - accuracy: 0.9159 - val_loss: 0.2694 - val_accuracy: 0.9048\nEpoch 2/3\n4210/4210 [==============================] - 542s 129ms/step - loss: 0.1180 - accuracy: 0.9584 - val_loss: 0.3046 - val_accuracy: 0.8830\nEpoch 3/3\n4210/4210 [==============================] - 541s 129ms/step - loss: 0.0829 - accuracy: 0.9712 - val_loss: 0.3386 - val_accuracy: 0.8807\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Step 5: Apply pruning (only to classification head)\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.0,\n        final_sparsity=0.5,\n        begin_step=0,\n        end_step=len(tf_train_dataset) * 3\n    )\n}\n\nwith contextlib.nullcontext():\n    # Create a new Functional model\n    input_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n    attention_mask = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n    transformer_outputs = baseline_model.distilbert(input_ids, attention_mask=attention_mask)[0]\n    cls_token = transformer_outputs[:, 0, :]  # Take [CLS] token\n    # Apply pruning to dense layers only\n    pre_classifier = tfmot.sparsity.keras.prune_low_magnitude(\n        tf.keras.layers.Dense(768, activation='relu', name='pre_classifier'),\n        **pruning_params\n    )(cls_token)\n    classifier = tfmot.sparsity.keras.prune_low_magnitude(\n        tf.keras.layers.Dense(2, name='classifier'),\n        **pruning_params\n    )(pre_classifier)\n    functional_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=classifier)\n\n    # Copy weights from baseline_model to functional_model\n    for layer in functional_model.layers:\n        if layer.name in ['pre_classifier', 'classifier']:\n            layer_wo_pruning = baseline_model.get_layer(layer.name)\n            layer.set_weights(layer_wo_pruning.get_weights())\n\n    # Compile and train the pruned model\n    functional_model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n    )\n    functional_model.fit(\n        tf_train_dataset,\n        validation_data=tf_validation_dataset,\n        epochs=3,\n        callbacks=[tfmot.sparsity.keras.UpdatePruningStep()]\n    )\n\n# Strip pruning wrappers\nfinal_pruned_model = tfmot.sparsity.keras.strip_pruning(functional_model)\nfinal_pruned_model.save('pruned_model', save_format='tf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T17:23:51.994841Z","iopub.execute_input":"2025-07-04T17:23:51.995552Z","iopub.status.idle":"2025-07-04T17:51:51.819349Z","shell.execute_reply.started":"2025-07-04T17:23:51.995525Z","shell.execute_reply":"2025-07-04T17:51:51.818700Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n4210/4210 [==============================] - 572s 130ms/step - loss: 0.0650 - accuracy: 0.9772 - val_loss: 0.4119 - val_accuracy: 0.8819\nEpoch 2/3\n4210/4210 [==============================] - 543s 129ms/step - loss: 0.0491 - accuracy: 0.9834 - val_loss: 0.4500 - val_accuracy: 0.8899\nEpoch 3/3\n4210/4210 [==============================] - 543s 129ms/step - loss: 0.0400 - accuracy: 0.9854 - val_loss: 0.5483 - val_accuracy: 0.8796\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Step 6: Knowledge Distillation\nteacher_model = tf.keras.models.load_model('baseline_model')\nteacher_model.trainable = False\nstudent_model = final_pruned_model\n\ndef kd_loss(y_true, student_logits, teacher_logits, alpha=0.5, T=2):\n    ce_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, student_logits, from_logits=True)\n    ce_loss = tf.reduce_mean(ce_loss)\n    \n    student_logits_soft = student_logits / T\n    teacher_logits_soft = teacher_logits / T\n    student_probs = tf.nn.softmax(student_logits_soft)\n    teacher_probs = tf.nn.softmax(teacher_logits_soft)\n    \n    kl_loss = tf.keras.losses.kullback_leibler_divergence(teacher_probs, student_probs)\n    kl_loss = tf.reduce_mean(kl_loss)\n    \n    return (1 - alpha) * ce_loss + alpha * (T ** 2) * kl_loss\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\nstudent_model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n\n# Custom training loop for KD\nepochs = 3\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    for step, (x_batch, y_batch) in enumerate(tf_train_dataset):\n        # Cast inputs to int32 and use correct input keys\n        x_batch_teacher = {\n            'input_ids': tf.cast(x_batch['input_ids'], tf.int32),\n            'attention_mask': tf.cast(x_batch['attention_mask'], tf.int32)\n        }\n        with tf.GradientTape() as tape:\n            student_outputs = student_model(x_batch, training=True)  # Functional model outputs logits directly\n            teacher_outputs = teacher_model(x_batch_teacher, training=False)  # Returns dict with 'logits'\n            loss = kd_loss(y_batch, student_outputs, teacher_outputs['logits'])\n        grads = tape.gradient(loss, student_model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n        if step % 100 == 0:\n            print(f\"Step {step}, Loss: {loss.numpy()}\")\n\nkd_optimized_model = student_model\nkd_optimized_model.save('kd_optimized_model', save_format='tf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T18:19:02.156239Z","iopub.execute_input":"2025-07-04T18:19:02.156827Z","iopub.status.idle":"2025-07-04T19:58:39.866468Z","shell.execute_reply.started":"2025-07-04T18:19:02.156792Z","shell.execute_reply":"2025-07-04T19:58:39.865761Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\nStep 0, Loss: 0.16732065379619598\nStep 100, Loss: 0.026963941752910614\nStep 200, Loss: 0.01869933307170868\nStep 300, Loss: 0.027217116206884384\nStep 400, Loss: 0.05904054641723633\nStep 500, Loss: 0.024975813925266266\nStep 600, Loss: 0.024407021701335907\nStep 700, Loss: 0.06021521985530853\nStep 800, Loss: 0.029428452253341675\nStep 900, Loss: 0.011104256846010685\nStep 1000, Loss: 0.14714956283569336\nStep 1100, Loss: 0.03795892000198364\nStep 1200, Loss: 0.19076687097549438\nStep 1300, Loss: 0.015826400369405746\nStep 1400, Loss: 0.053613483905792236\nStep 1500, Loss: 0.03071068599820137\nStep 1600, Loss: 0.10823647677898407\nStep 1700, Loss: 0.024124812334775925\nStep 1800, Loss: 0.02397768571972847\nStep 1900, Loss: 0.014237001538276672\nStep 2000, Loss: 0.029408998787403107\nStep 2100, Loss: 0.020773548632860184\nStep 2200, Loss: 0.013111310079693794\nStep 2300, Loss: 0.05062306672334671\nStep 2400, Loss: 0.05708516389131546\nStep 2500, Loss: 0.14544281363487244\nStep 2600, Loss: 0.011217744089663029\nStep 2700, Loss: 0.09353314340114594\nStep 2800, Loss: 0.07366485148668289\nStep 2900, Loss: 0.012698989361524582\nStep 3000, Loss: 0.0719766765832901\nStep 3100, Loss: 0.01280137524008751\nStep 3200, Loss: 0.38726624846458435\nStep 3300, Loss: 0.047215186059474945\nStep 3400, Loss: 0.01621146872639656\nStep 3500, Loss: 0.027569804340600967\nStep 3600, Loss: 0.046701960265636444\nStep 3700, Loss: 0.017387595027685165\nStep 3800, Loss: 0.0318022295832634\nStep 3900, Loss: 0.12008583545684814\nStep 4000, Loss: 0.017552725970745087\nStep 4100, Loss: 0.03252200782299042\nStep 4200, Loss: 0.019197693094611168\nEpoch 2/3\nStep 0, Loss: 0.011509617790579796\nStep 100, Loss: 0.0053681787103414536\nStep 200, Loss: 0.044390179216861725\nStep 300, Loss: 0.010585490614175797\nStep 400, Loss: 0.0023026023991405964\nStep 500, Loss: 0.009806586429476738\nStep 600, Loss: 0.02800174616277218\nStep 700, Loss: 0.012165550142526627\nStep 800, Loss: 0.03551877290010452\nStep 900, Loss: 0.013866722583770752\nStep 1000, Loss: 0.008312058635056019\nStep 1100, Loss: 0.006148073822259903\nStep 1200, Loss: 0.03150736913084984\nStep 1300, Loss: 0.026219984516501427\nStep 1400, Loss: 0.018552662804722786\nStep 1500, Loss: 0.026760661974549294\nStep 1600, Loss: 0.04395238310098648\nStep 1700, Loss: 0.03921011835336685\nStep 1800, Loss: 0.02547661028802395\nStep 1900, Loss: 0.006738755851984024\nStep 2000, Loss: 0.023371435701847076\nStep 2100, Loss: 0.025788288563489914\nStep 2200, Loss: 0.02523033507168293\nStep 2300, Loss: 0.0659642443060875\nStep 2400, Loss: 0.017727892845869064\nStep 2500, Loss: 0.04871232062578201\nStep 2600, Loss: 0.025612017139792442\nStep 2700, Loss: 0.0037632682360708714\nStep 2800, Loss: 0.01099019218236208\nStep 2900, Loss: 0.0522492378950119\nStep 3000, Loss: 0.040179938077926636\nStep 3100, Loss: 0.06640621274709702\nStep 3200, Loss: 0.0053009032271802425\nStep 3300, Loss: 0.017743410542607307\nStep 3400, Loss: 0.008719181641936302\nStep 3500, Loss: 0.01574554294347763\nStep 3600, Loss: 0.04898854345083237\nStep 3700, Loss: 0.057517170906066895\nStep 3800, Loss: 0.27711543440818787\nStep 3900, Loss: 0.03447571396827698\nStep 4000, Loss: 0.06904394179582596\nStep 4100, Loss: 0.013494698330760002\nStep 4200, Loss: 0.059864260256290436\nEpoch 3/3\nStep 0, Loss: 0.02856612764298916\nStep 100, Loss: 0.022237595170736313\nStep 200, Loss: 0.03776390850543976\nStep 300, Loss: 0.0020917507354170084\nStep 400, Loss: 0.021270066499710083\nStep 500, Loss: 0.01635913923382759\nStep 600, Loss: 0.17803041636943817\nStep 700, Loss: 0.09843394160270691\nStep 800, Loss: 0.005563698709011078\nStep 900, Loss: 0.02112460881471634\nStep 1000, Loss: 0.03362370282411575\nStep 1100, Loss: 0.041145630180835724\nStep 1200, Loss: 0.008990095928311348\nStep 1300, Loss: 0.021578343585133553\nStep 1400, Loss: 0.07408296316862106\nStep 1500, Loss: 0.025227412581443787\nStep 1600, Loss: 0.03481458127498627\nStep 1700, Loss: 0.027397990226745605\nStep 1800, Loss: 0.009366963058710098\nStep 1900, Loss: 0.01124775130301714\nStep 2000, Loss: 0.06307245045900345\nStep 2100, Loss: 0.03257281705737114\nStep 2200, Loss: 0.034302614629268646\nStep 2300, Loss: 0.03226446360349655\nStep 2400, Loss: 0.3334542214870453\nStep 2500, Loss: 0.012814056128263474\nStep 2600, Loss: 0.007428569253534079\nStep 2700, Loss: 0.05757530778646469\nStep 2800, Loss: 0.017437828704714775\nStep 2900, Loss: 0.0046673184260725975\nStep 3000, Loss: 0.04300159960985184\nStep 3100, Loss: 0.017345726490020752\nStep 3200, Loss: 0.007951634004712105\nStep 3300, Loss: 0.012502542696893215\nStep 3400, Loss: 0.06718695163726807\nStep 3500, Loss: 0.021345390006899834\nStep 3600, Loss: 0.045593395829200745\nStep 3700, Loss: 0.06751195341348648\nStep 3800, Loss: 0.016978062689304352\nStep 3900, Loss: 0.06707148253917694\nStep 4000, Loss: 0.032849013805389404\nStep 4100, Loss: 0.07171426713466644\nStep 4200, Loss: 0.2307548075914383\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Step 7: Post-Training Quantization\ncalibration_data = tokenized_datasets[\"train\"].select(range(100))\n\ndef representative_dataset():\n    for i in range(100):\n        sample = calibration_data[i]\n        yield [\n            np.array(sample['input_ids'], dtype=np.int32)[np.newaxis, :],\n            np.array(sample['attention_mask'], dtype=np.int32)[np.newaxis, :]\n        ]\n\nconverter = tf.lite.TFLiteConverter.from_saved_model('kd_optimized_model')\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_dataset\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.int8\nconverter.inference_output_type = tf.int8\ntflite_model = converter.convert()\n\nwith open('tflite_model.tflite', 'wb') as f:\n    f.write(tflite_model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T20:01:41.075570Z","iopub.execute_input":"2025-07-04T20:01:41.076135Z","iopub.status.idle":"2025-07-04T20:04:02.107179Z","shell.execute_reply.started":"2025-07-04T20:01:41.076112Z","shell.execute_reply":"2025-07-04T20:04:02.106350Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1751659338.021151      35 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1751659338.021202      35 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1751659338.153981      35 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\nfully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Step 8: Evaluation\ndef compute_accuracy(model, dataset):\n    total_correct = 0\n    total_samples = 0\n    for x_batch, y_batch in dataset:\n        # Adjust input for teacher model (TFDistilBertForSequenceClassification)\n        x_batch_input = {\n            'input_ids': tf.cast(x_batch['input_ids'], tf.int32),\n            'attention_mask': tf.cast(x_batch['attention_mask'], tf.int32)\n        } if isinstance(model, TFDistilBertForSequenceClassification) else x_batch\n        outputs = model(x_batch_input, training=False)\n        logits = outputs['logits'] if isinstance(outputs, dict) else outputs\n        predictions = tf.argmax(logits, axis=1)\n        total_correct += tf.reduce_sum(tf.cast(predictions == y_batch, tf.int32)).numpy()\n        total_samples += y_batch.shape[0]\n    return total_correct / total_samples\n\ndef compute_tflite_accuracy(tflite_model_path, dataset):\n    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    \n    total_correct = 0\n    total_samples = 0\n    for x_batch, y_batch in dataset:\n        for i in range(x_batch['input_ids'].shape[0]):\n            interpreter.set_tensor(input_details[0]['index'], tf.cast(x_batch['input_ids'][i:i+1], tf.int32))\n            interpreter.set_tensor(input_details[1]['index'], tf.cast(x_batch['attention_mask'][i:i+1], tf.int32))\n            interpreter.invoke()\n            logits = interpreter.get_tensor(output_details[0]['index'])\n            prediction = np.argmax(logits, axis=1)\n            total_correct += (prediction == y_batch[i].numpy()).sum()\n            total_samples += 1\n    return total_correct / total_samples\n\ndef measure_inference_time(model, dataset, num_samples=100):\n    start_time = time.time()\n    count = 0\n    for x_batch, _ in dataset:\n        x_batch_input = {\n            'input_ids': tf.cast(x_batch['input_ids'], tf.int32),\n            'attention_mask': tf.cast(x_batch['attention_mask'], tf.int32)\n        } if isinstance(model, TFDistilBertForSequenceClassification) else x_batch\n        outputs = model(x_batch_input, training=False)\n        count += x_batch['input_ids'].shape[0]\n        if count >= num_samples:\n            break\n    return (time.time() - start_time) / num_samples * 1000  # ms per sample\n\ndef measure_tflite_inference_time(tflite_model_path, dataset, num_samples=100):\n    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    start_time = time.time()\n    count = 0\n    for x_batch, _ in dataset:\n        for i in range(x_batch['input_ids'].shape[0]):\n            interpreter.set_tensor(input_details[0]['index'], tf.cast(x_batch['input_ids'][i:i+1], tf.int32))\n            interpreter.set_tensor(input_details[1]['index'], tf.cast(x_batch['attention_mask'][i:i+1], tf.int32))\n            interpreter.invoke()\n            count += 1\n            if count >= num_samples:\n                break\n    return (time.time() - start_time) / num_samples * 1000  # ms per sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T20:05:34.342683Z","iopub.execute_input":"2025-07-04T20:05:34.343274Z","iopub.status.idle":"2025-07-04T20:05:34.354472Z","shell.execute_reply.started":"2025-07-04T20:05:34.343249Z","shell.execute_reply":"2025-07-04T20:05:34.353693Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Compute metrics\nbaseline_model = tf.keras.models.load_model('baseline_model')\npruned_model = tf.keras.models.load_model('pruned_model')\nkd_optimized_model = tf.keras.models.load_model('kd_optimized_model')\n\nbaseline_accuracy = compute_accuracy(baseline_model, tf_validation_dataset)\npruned_accuracy = compute_accuracy(pruned_model, tf_validation_dataset)\nkd_accuracy = compute_accuracy(kd_optimized_model, tf_validation_dataset)\ntflite_accuracy = compute_tflite_accuracy('tflite_model.tflite', tf_validation_dataset)\n\nbaseline_size = sum(os.path.getsize(os.path.join('baseline_model', f)) for f in os.listdir('baseline_model') if os.path.isfile(os.path.join('baseline_model', f))) / (1024 * 1024)  # MB\npruned_size = sum(os.path.getsize(os.path.join('pruned_model', f)) for f in os.listdir('pruned_model') if os.path.isfile(os.path.join('pruned_model', f))) / (1024 * 1024)  # MB\nkd_size = sum(os.path.getsize(os.path.join('kd_optimized_model', f)) for f in os.listdir('kd_optimized_model') if os.path.isfile(os.path.join('kd_optimized_model', f))) / (1024 * 1024)  # MB\ntflite_size = os.path.getsize('tflite_model.tflite') / (1024 * 1024)  # MB\n\nbaseline_latency = measure_inference_time(baseline_model, tf_validation_dataset)\npruned_latency = measure_inference_time(pruned_model, tf_validation_dataset)\nkd_latency = measure_inference_time(kd_optimized_model, tf_validation_dataset)\ntflite_latency = measure_tflite_inference_time('tflite_model.tflite', tf_validation_dataset)\n\n# Step 9: Plotting\nmetrics = {\n    'Model': ['Baseline', 'Pruned', 'Distilled', 'Quantized'],\n    'Accuracy': [baseline_accuracy * 100, pruned_accuracy * 100, kd_accuracy * 100, tflite_accuracy * 100],\n    'Size (MB)': [baseline_size, pruned_size, kd_size, tflite_size],\n    'Latency (ms)': [baseline_latency, pruned_latency, kd_latency, tflite_latency]\n}\n\n# Note: The actual plotting is handled by the ChartJS block below\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 3, 1)\nplt.bar(metrics['Model'], metrics['Accuracy'])\nplt.title('Accuracy (%)')\nplt.subplot(1, 3, 2)\nplt.bar(metrics['Model'], metrics['Size (MB)'])\nplt.title('Model Size (MB)')\nplt.subplot(1, 3, 3)\nplt.bar(metrics['Model'], metrics['Latency (ms)'])\nplt.title('Inference Latency (ms)')\nplt.tight_layout()\nplt.show()\n\nprint(\"Metrics Table:\")\nprint(\"| Model     | Accuracy (%) | Size (MB) | Latency (ms) |\")\nprint(\"|-----------|--------------|-----------|--------------|\")\nfor i in range(4):\n    print(f\"| {metrics['Model'][i]:<9} | {metrics['Accuracy'][i]:<12.2f} | {metrics['Size (MB)'][i]:<9.2f} | {metrics['Latency (ms)'][i]:<12.2f} |\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T20:06:04.563854Z","iopub.execute_input":"2025-07-04T20:06:04.564123Z"}},"outputs":[{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n","output_type":"stream"}],"execution_count":null}]}
